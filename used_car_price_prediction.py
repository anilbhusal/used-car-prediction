# -*- coding: utf-8 -*-
"""Used car price prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EQrSqsO5muZQRsBmijjGcFeJ0-SrnMyY

# Data Preprocessing

dataset: https://www.kaggle.com/datasets/nehalbirla/vehicle-dataset-from-cardekho

## Importing libraries and Dataset
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

dataset = pd.read_csv('/content/car data.csv')

"""## Data Exploration"""

dataset.head()

dataset.shape

dataset.columns

dataset.info()

# categorical data
dataset.select_dtypes(include = 'object').columns

len(dataset.select_dtypes(include = 'object').columns)

# Numerical data
dataset.select_dtypes(include = ['int64','float64']).columns

len(dataset.select_dtypes(include = ['int64','float64']).columns)

dataset.describe()

"""## Dealing with missing values"""

dataset.isnull().values.any()

dataset.isnull().values.sum()

"""## Restructure the dataset"""

dataset.head()

dataset = dataset.drop(columns = 'Car_Name')

dataset.head()

# add a column
dataset['Current Year'] = 2024

dataset.head()

dataset['Years Old'] = dataset['Current Year'] - dataset['Year']

dataset.head()

dataset = dataset.drop(columns = ['Year', 'Current Year'])

dataset.head()

"""## Encoding the categorical data"""

dataset.head()

dataset.select_dtypes(include = 'object').columns

len(dataset.select_dtypes(include = 'object').columns)

dataset['Fuel_Type'].nunique()

dataset['Seller_Type'].nunique()

dataset['Transmission'].nunique()

dataset.shape

# one hot encoding
dataset = pd.get_dummies(data = dataset, drop_first =True, dtype= int)

dataset.head()

dataset.shape

"""## Correlation Matrix"""

dataset_2 = dataset.drop(columns = 'Selling_Price')

dataset_2.corrwith(dataset['Selling_Price']).plot.bar(
    figsize = (16,9), title = 'Correlated with Selling Price', grid=True
)

corr = dataset.corr()

# Heatmap
plt.figure(figsize = (16,9))
sns.heatmap(corr, annot =True)

"""## Splittig the dataset"""

dataset.head()

# Matrix of features/
x = dataset.drop(columns = 'Selling_Price')

# Target variable
y = dataset['Selling_Price']

from sklearn.model_selection import train_test_split

x_train, x_test, y_train, y_test  = train_test_split(x,y,test_size = 0.2, random_state = 0)

x_train.shape

x_test.shape

y_train.shape

y_test.shape

"""## feature scaling

we are not applying feature scaling for this specific problem

# Building the model

## Multiple linear regression
"""

from sklearn.linear_model import LinearRegression
regressor_mlr= LinearRegression()
regressor_mlr.fit(x_train,y_train)

y_pred = regressor_mlr.predict(x_test)

from sklearn.metrics import r2_score

r2_score(y_test,y_pred)

"""## Random Forest Regression"""

from sklearn.ensemble import RandomForestRegressor
regressor_rf = RandomForestRegressor()
regressor_rf.fit(x_train,y_train)

y_pred = regressor_rf.predict(x_test)

from sklearn.metrics import r2_score

r2_score(y_test,y_pred)

"""# Parameter tuning using RandomizedSearchCV"""

from sklearn.model_selection import RandomizedSearchCV

parameters ={
    'n_estimators':[100,200,300,400,500,600,700,800,900,1000],
    'max_depth' : [10,20,30,40,50,],
    'min_samples_leaf' : [1,2,5,10],
    'max_features' : ['auto','sqrt', 'log2']
}

parameters

random_cv = RandomizedSearchCV(estimator = regressor_rf, param_distributions=parameters, n_iter =10, scoring = 'neg_mean_absolute_error', cv=5, verbose =2, n_jobs =-1)

random_cv.fit(x_train,y_train)

random_cv.best_estimator_

random_cv.best_params_

random_cv.best_score_

"""# Final Model (Random Forest)"""

from sklearn.ensemble import RandomForestRegressor
regressor = RandomForestRegressor(max_depth=40, max_features='auto', n_estimators=1000, random_state = 0)
regressor.fit(x_train,y_train)

y_pred = regressor.predict(x_test)

from sklearn.metrics import r2_score

r2_score(y_test,y_pred)

"""# Predicting single observation"""

dataset.head()

single_obs = [[8.54,3500,0,6,1,0,0,1]]

single_obs

regressor.predict(single_obs)

"""so the selling price is 7.33987"""